{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduled Scoring with Prefect on Saturn Cloud\n",
    "\n",
    "This notebook contains sample code to take a `prefect` flow and distribute its work with a `Dask` cluster. The flow below mocks the process of measuring the effectiveness of a deployed statistical model.\n",
    "\n",
    "### Model Details\n",
    "\n",
    "The data used for this example is the **\"Incident management process enriched event log\"** dataset [from the UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Incident+management+process+enriched+event+log).That dataset contains tickets from an IT support system, including characteristics like the priority of the ticket, the time it was opened, and the time it was closed.\n",
    "\n",
    "This dataset can be used to solve a regression task:\n",
    "\n",
    "> Given the characteristics of a ticket, how long will it be until it is closed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "The code in this notebook uses `prefect` for orchestration *(figuring out what to do, and in what order)* and `dask` for execution *(doing the things)*.\n",
    "\n",
    "It relies on the following additional non-builtin libraries:\n",
    "\n",
    "* `numpy`: data manipulation\n",
    "* `pandas`: data manipulation\n",
    "* `requests`: read in data from the internet\n",
    "* `scikit-learn`: evaluation metric functions\n",
    "* `dask-saturn`: create and interact with Saturn Cloud `Dask` clusters ([link](https://github.com/saturncloud/dask-saturn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import prefect\n",
    "import numpy as np\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from io import BytesIO\n",
    "from prefect import task, Parameter, Task, Flow\n",
    "from prefect.engine.executors.dask import DaskExecutor\n",
    "from prefect.schedules import IntervalSchedule\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask_saturn import SaturnCluster\n",
    "from dask import delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Tasks\n",
    "\n",
    "`prefect` refers to a workload as a \"flow\", which comprises multiple individual things to do called \"tasks\". From [the Prefect docs](https://docs.prefect.io/core/concepts/tasks.html):\n",
    "\n",
    "> A task is like a function: it optionally takes inputs, performs an action, and produces an optional result.\n",
    "\n",
    "The goal of this notebooks flow is to evaluate, on an ongoing basis, the performance of a model that predicts time-to-close for tickets in an IT support system.\n",
    "\n",
    "That can be broken down into the following tasks\n",
    "\n",
    "* `get_trial_id()`: assign a unique ID to each run\n",
    "* `get_ticket_data_batch()`: get a random set of newly-closed tickets\n",
    "* `get_target()`: given a batch of tickets, compute how long it took to close them\n",
    "* `predict()`: predict the time-to-close, using the heuristic \"higher-priority tickets close faster\"\n",
    "* `evaluate_model()`: compute evaluation metrics comparing predicted and actual time-to-close\n",
    "* `get_trial_summary()`: collect all evaluation metrics in one object\n",
    "* `write_trial_summary()`: write trial results somewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def get_trial_id() -> str:\n",
    "    \"\"\"\n",
    "    Generate a unique identifier for this trial.\n",
    "    \"\"\"\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "\n",
    "@task\n",
    "def get_ticket_data_batch(batch_size: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate the experience of getting a random sample of new tickets\n",
    "    from an IT system, to test the performance of a model.\n",
    "    \"\"\"\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00498/incident_event_log.zip\"\n",
    "    resp = requests.get(url)\n",
    "    zipfile = ZipFile(BytesIO(resp.content))\n",
    "    data_file = \"incident_event_log.csv\"\n",
    "    # _date_parser has to be a lambda or pandas won't convert dates correctly\n",
    "    _date_parser = lambda x: pd.NaT if x == '?' else datetime.strptime(x, \"%d/%m/%Y %H:%M\")\n",
    "    df = pd.read_csv(\n",
    "        zipfile.open(data_file),\n",
    "        parse_dates=[\n",
    "            \"opened_at\",\n",
    "            \"resolved_at\",\n",
    "            \"closed_at\",\n",
    "            \"sys_created_at\",\n",
    "            \"sys_updated_at\"\n",
    "        ],\n",
    "        infer_datetime_format=False,\n",
    "        converters={\n",
    "            \"opened_at\": _date_parser,\n",
    "            \"resolved_at\": _date_parser,\n",
    "            \"closed_at\": _date_parser,\n",
    "            \"sys_created_at\": _date_parser,\n",
    "            \"sys_updated_at\": _date_parser\n",
    "        },\n",
    "        na_values = ['?']\n",
    "    )\n",
    "    df[\"sys_updated_at\"] = pd.to_datetime(df[\"sys_updated_at\"])\n",
    "    rows_to_score = np.random.randint(0, df.shape[0], 100)\n",
    "    return(df.iloc[rows_to_score])\n",
    "\n",
    "\n",
    "@task\n",
    "def get_target(df):\n",
    "    \"\"\"\n",
    "    Compute time-til-close on a data frame of tickets\n",
    "    \"\"\"\n",
    "    time_til_close = (df['closed_at'] - df['sys_updated_at']) / np.timedelta64(1, 's')\n",
    "    return time_til_close\n",
    "\n",
    "\n",
    "@task\n",
    "def predict(df):\n",
    "    \"\"\"\n",
    "    Given an input data frame, predict how long it will be until the ticket is closed.\n",
    "    For simplicity, using a super simple model that just says\n",
    "    \"high-priority tickets get closed faster\".\n",
    "    \"\"\"\n",
    "    seconds_in_an_hour = 60.0 * 60.0\n",
    "    preds = df[\"priority\"].map({\n",
    "        \"1 - Critical\":   6.0 * seconds_in_an_hour,\n",
    "        \"2 - High\":      24.0 * seconds_in_an_hour,\n",
    "        \"3 - Moderate\": 120.0 * seconds_in_an_hour,\n",
    "        \"4 - Lower\":    240.0 * seconds_in_an_hour,\n",
    "    })\n",
    "    default_guess_for_no_priority = 180.0 * seconds_in_an_hour\n",
    "    preds = preds.fillna(default_guess_for_no_priority)\n",
    "    return(preds)\n",
    "\n",
    "\n",
    "@task\n",
    "def evaluate_model(y_true, y_pred, metric_name: str) -> float:\n",
    "    metric_func_lookup = {\n",
    "        \"mae\": mean_absolute_error,\n",
    "        \"medae\": median_absolute_error,\n",
    "        \"mse\": mean_squared_error,\n",
    "        \"r2\": r2_score\n",
    "    }\n",
    "    metric_func = metric_func_lookup[metric_name]\n",
    "    return metric_func(y_true, y_pred)\n",
    "\n",
    "\n",
    "@task\n",
    "def get_trial_summary(trial_id:str, actuals, input_df: pd.DataFrame, metrics: dict) -> dict:\n",
    "    out = {\"id\": trial_id}\n",
    "    out[\"data\"] = {\n",
    "        \"num_obs\": input_df.shape[0],\n",
    "        \"metrics\": metrics,\n",
    "        \"target\": {\n",
    "            \"mean\": actuals.mean(),\n",
    "            \"median\": actuals.median(),\n",
    "            \"min\": actuals.min(),\n",
    "            \"max\": actuals.max()\n",
    "        }\n",
    "    }\n",
    "    return out\n",
    "\n",
    "\n",
    "@task(log_stdout=True)\n",
    "def write_trial_summary(trial_summary: str):\n",
    "    \"\"\"\n",
    "    Write out a summary of the file. Currently just logs back to the\n",
    "    Prefect logger\n",
    "    \"\"\"\n",
    "    logger = prefect.context.get(\"logger\")\n",
    "    logger.info(json.dumps(trial_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a Flow\n",
    "\n",
    "Now that all of the task logic has been defined, the next step is to compose those tasks into a \"flow\". From [the Prefect docs](https://docs.prefect.io/core/concepts/flows.html):\n",
    "\n",
    "> A Flow is a container for Tasks. It represents an entire workflow or application by describing the dependencies between tasks.\n",
    "\n",
    "> Flows are DAGs, or \"directed acyclic graphs.\" This is a mathematical way of describing certain organizational principles:\n",
    "\n",
    "> * A graph is a data structure that uses \"edges\" to connect \"nodes.\" Prefect models each Flow as a graph in which Task dependencies are modeled by Edges.\n",
    "> * A directed graph means that edges have a start and an end: when two tasks are connected, one of them unambiguously runs first and the other one runs second.\n",
    "> * An acyclic directed graph has no circular dependencies: if you walk through the graph, you will never revisit a task you've seen before.\n",
    "\n",
    "Because we want this job to run on a schedule, the code below provides one additional argument to `Flow()`, a special \"schedule\" object. In this case, the code below says \"run this flow every minute\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = IntervalSchedule(\n",
    "    interval=timedelta(minutes=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: `prefect` flows do not have to be run on a schedule. To test a single run, just omit `schedule` from the code block below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Flow('ticket-model-evaluation', schedule) as flow:\n",
    "    batch_size = Parameter(\n",
    "        'batch-size',\n",
    "        default=1000\n",
    "    )\n",
    "    trial_id = get_trial_id()\n",
    "    \n",
    "    # pull sample data\n",
    "    sample_ticket_df = get_ticket_data_batch(batch_size)\n",
    "\n",
    "    # compute target\n",
    "    actuals = get_target(sample_ticket_df)\n",
    "    \n",
    "    # get prediction\n",
    "    preds = predict(sample_ticket_df)\n",
    "    \n",
    "    # compute evaluation metrics\n",
    "    mae = evaluate_model(actuals, preds, \"mae\")\n",
    "    medae = evaluate_model(actuals, preds, \"medae\")\n",
    "    mse = evaluate_model(actuals, preds, \"mse\")\n",
    "    r2 = evaluate_model(actuals, preds, \"r2\")\n",
    "    \n",
    "    # get trial summary in a string\n",
    "    trial_summary = get_trial_summary(\n",
    "        trial_id=trial_id,\n",
    "        input_df=sample_ticket_df,\n",
    "        actuals=actuals,\n",
    "        metrics={\n",
    "            \"MAE\": mae,\n",
    "            \"MedAE\": medae,\n",
    "            \"MSE\": mse,\n",
    "            \"R2\": r2\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # store trial summary\n",
    "    trial_complete = write_trial_summary(trial_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have all of the work defined in tasks and arranged within a flow, but none of the tasks have run yet. In the next section, we'll do that using `Dask`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the flow with Dask\n",
    "\n",
    "If you run `flow.visualize()` on the code above, you'll see that this flow is not linear. Some tasks are independent of others, and can be run at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dask` is a framework that runs graphs like the one above. Saturn makes it easy to create and manage Dask clusters. The code below will create a Dask cluster with two workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SaturnCluster()\n",
    "cluster.scale(2)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to tell `prefect` to use this `Dask` cluster to do work! This is done with something called an \"executor\". From the [Prefect docs]():\n",
    "\n",
    "> Prefect Executors implement the logic for how Tasks are run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = DaskExuector(\n",
    "    address=cluster.scheduler_address\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the flow! The code below will pass all of the tasks to the `Dask` cluster you created above. Because `flow` was defined with an `IntervalSchedule`, it will run continuously, and will re-run all the tasks every minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow.run(\n",
    "    executor=executor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move From Testing to Deployment\n",
    "\n",
    "Using `flow.run()` in a notebook is excellent for testing, but once you are confident that this code is doing what you expect, you will probably want to run it in an automated, isolated environment.\n",
    "\n",
    "Return to [\"Using a scheduled prefect flow with a Saturn Dask cluster\"]() to see how to take the code we've developed and run it as **Custom Deployment** in Saturn Cloud."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
