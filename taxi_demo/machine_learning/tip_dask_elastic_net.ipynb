{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "## Dask\n",
    "\n",
    "**Hardware**: 10 nodes - r5.8xlarge's (32 CPU, 256 GB RAM each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils import MLUtils\n",
    "\n",
    "ml_utils = MLUtils(\n",
    "    ml_task='tip',\n",
    "    tool='dask',\n",
    "    model='elastic_net',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-08-06 23:25:08] WARNING - dask-saturn | Unable to update the specification of a running dask cluster. No changes applied. To update, first stop the cluster with `cluster.close()` and reinitialize, or run 'cluster = SaturnCluster.reset(**kwargs)' to restart automatically.\n",
      "[2020-08-06 23:25:08] INFO - dask-saturn | Cluster is ready\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b73d8081ba494da8374f563b5712e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SaturnCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_saturn import SaturnCluster\n",
    "\n",
    "cluster = SaturnCluster(n_workers=10, scheduler_size='xlarge', worker_size='8xlarge', nthreads=32)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 70.9 ms, sys: 9.36 ms, total: 80.3 ms\n",
      "Wall time: 2.42 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10994913"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tip_train = dd.read_parquet(f'{ml_utils.taxi_path}/data/ml/tip_train_sample', engine='pyarrow')\n",
    "len(tip_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pickup_taxizone_id</th>\n",
       "      <th>dropoff_taxizone_id</th>\n",
       "      <th>pickup_weekday</th>\n",
       "      <th>pickup_weekofyear</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_minute</th>\n",
       "      <th>pickup_week_hour</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>tip_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28a18fa5fa2f44f29ffd98fc9159829d</td>\n",
       "      <td>238.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a6578145ff824f5fb94e90457b040883</td>\n",
       "      <td>236.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91726ecac3b44e8bbfea68d725f35556</td>\n",
       "      <td>90.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>166</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a3b0d14ad1644dd6b90f1af6be002e55</td>\n",
       "      <td>141.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>34</td>\n",
       "      <td>153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70aa5a0c6bc147dd8553e201b63ba0fe</td>\n",
       "      <td>100.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.169231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  pickup_taxizone_id  dropoff_taxizone_id  \\\n",
       "0  28a18fa5fa2f44f29ffd98fc9159829d               238.0                132.0   \n",
       "1  a6578145ff824f5fb94e90457b040883               236.0                246.0   \n",
       "2  91726ecac3b44e8bbfea68d725f35556                90.0                148.0   \n",
       "3  a3b0d14ad1644dd6b90f1af6be002e55               141.0                186.0   \n",
       "4  70aa5a0c6bc147dd8553e201b63ba0fe               100.0                142.0   \n",
       "\n",
       "   pickup_weekday  pickup_weekofyear  pickup_hour  pickup_minute  \\\n",
       "0               0                 29            7             19   \n",
       "1               6                 28            9             16   \n",
       "2               6                 28           22             44   \n",
       "3               6                 28            9             34   \n",
       "4               6                 28           22              7   \n",
       "\n",
       "   pickup_week_hour  passenger_count  tip_fraction  \n",
       "0                 7              1.0      0.199616  \n",
       "1               153              1.0      0.130435  \n",
       "2               166              6.0      0.166667  \n",
       "3               153              1.0      0.152299  \n",
       "4               166              1.0      0.169231  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tip_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's take the same sample we used in the single node scikit example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1099492"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = tip_train.sample(frac=0.1, replace=False, random_state=42)\n",
    "len(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run grid search\n",
    "\n",
    "- use `dask-ml` preprocessing and grid search classes\n",
    "- still using `sklearn.linear_model.ElasticNet` for model fitting\n",
    "- we won't `refit` with best model, because we want to use `dask_ml.wrappers.ParallelPostFit` to use dask to parallelize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from dask_ml.compose import ColumnTransformer\n",
    "from dask_ml.preprocessing import StandardScaler, DummyEncoder, Categorizer\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "\n",
    "features = ml_utils.tip_vars.features\n",
    "y_col = ml_utils.tip_vars.y_col\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('categorize', Categorizer(columns=ml_utils.tip_vars.categorical_feat)),\n",
    "    ('onehot', DummyEncoder(columns=ml_utils.tip_vars.categorical_feat)),\n",
    "    ('scale', ColumnTransformer(transformers=[('num', StandardScaler(), ml_utils.tip_vars.numeric_feat)])),\n",
    "    ('clf', ElasticNet(normalize=False, max_iter=100)),\n",
    "])\n",
    "\n",
    "params = ml_utils.tip_vars.elastic_net_grid_search_params\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params, cv=3, scoring='neg_mean_squared_error', refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.1 ms, sys: 4.84 ms, total: 39 ms\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = grid_search.fit(sample[features], sample[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best_params manually because we set `refit=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = (pd.DataFrame(grid_search.cv_results_)\n",
    "               .sort_values('mean_test_score', ascending=False)\n",
    "               .loc[0, 'params'])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "This wrapper allows us to parallelize predictions using Dask. The `fit` step is not affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 359 ms, sys: 260 ms, total: 619 ms\n",
      "Wall time: 8.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from dask_ml.wrappers import ParallelPostFit\n",
    "\n",
    "best_estimator = ParallelPostFit(estimator=pipeline)\n",
    "_ = best_estimator.fit(sample[features], sample[y_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Grab the sklearn estimator out of the dask wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator = best_estimator.estimator.named_steps['clf']\n",
    "ml_utils.write_model(sklearn_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test set\n",
    "\n",
    "And calculate metrics. Save predictions and metrics to S3.\n",
    "\n",
    "Notice that the below cell runs super fast, because it hasn't actually done anything due to Dask's lazy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 123 ms, sys: 0 ns, total: 123 ms\n",
      "Wall time: 684 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "amt_test = dd.read_parquet(f'{ml_utils.taxi_path}/data/ml/tip_test', engine='pyarrow')\n",
    "preds = amt_test[['id', y_col]].copy()\n",
    "preds.columns = ['id', 'actual']\n",
    "preds = preds.assign(predicted=best_estimator.predict(amt_test[features]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can `persist` the DataFrame to compute all the predictions and store in RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 70.6 ms, sys: 0 ns, total: 70.6 ms\n",
      "Wall time: 6.57 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8e8109754e3e4cb7879c4e9ee216d58d</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.153217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a30e7c87866f417ab15dee5617f272a0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.153217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1a7a611d0809489d99a5120727e0476a</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.153217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>736e84ca12a640cc858c210bd58f744c</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0.153217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f2c24299d9a34ce986b7a271c5cc80b2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id    actual  predicted\n",
       "0  8e8109754e3e4cb7879c4e9ee216d58d  0.097087   0.153217\n",
       "1  a30e7c87866f417ab15dee5617f272a0  0.166667   0.153217\n",
       "2  1a7a611d0809489d99a5120727e0476a  0.120000   0.153217\n",
       "3  736e84ca12a640cc858c210bd58f744c  0.089474   0.153217\n",
       "4  f2c24299d9a34ce986b7a271c5cc80b2  0.000000   0.153217"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from dask.distributed import wait\n",
    "preds = preds.persist()\n",
    "_ = wait(preds)\n",
    "\n",
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.4 ms, sys: 0 ns, total: 37.4 ms\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ml_utils.write_predictions(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "If the `preds` DataFrame was _really_ big, you would want to use `dask_ml.metrics.mean_squared_error`. Here, the `preds` columns are pulled down to the client because we're using `sklearn.metrics.mean_squared_error`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 558 ms, sys: 933 ms, total: 1.49 s\n",
      "Wall time: 2.28 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ml_task</th>\n",
       "      <th>tool</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tip</td>\n",
       "      <td>dask</td>\n",
       "      <td>elastic_net</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.052227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ml_task  tool        model metric     value\n",
       "0     tip  dask  elastic_net   rmse  0.052227"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = mean_squared_error(preds.actual, preds.predicted, squared=False)\n",
    "ml_utils.write_metric_df('rmse', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
